{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zC0JFc_J8sL9"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig, RobertaForQuestionAnswering, squad_convert_examples_to_features\n",
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "\n",
    "# Create logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MrI7mfsV_8ZX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that cuda is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s5rbbS_S9dSp"
   },
   "outputs": [],
   "source": [
    "%mkdir -p squad_data model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l6NXohYG9lRC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Homework_1_⚡️.ipynb  '(results).py'      train-step-losses.csv\r\n",
      " \u001b[0m\u001b[01;34mmodel_weights\u001b[0m/        \u001b[01;34msquad_data\u001b[0m/\r\n",
      " \u001b[01;34mprediction_outputs\u001b[0m/   train_dataset.pt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "18TpmmEr9nNv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-15 09:28:21--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 2606:50c0:8000::153, 2606:50c0:8003::153, 2606:50c0:8002::153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|2606:50c0:8000::153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42123633 (40M) [application/json]\n",
      "Saving to: ‘squad_data/train-v2.0.json’\n",
      "\n",
      "train-v2.0.json     100%[===================>]  40.17M  26.3MB/s    in 1.5s    \n",
      "\n",
      "2023-02-15 09:28:24 (26.3 MB/s) - ‘squad_data/train-v2.0.json’ saved [42123633/42123633]\n",
      "\n",
      "--2023-02-15 09:28:25--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 2606:50c0:8000::153, 2606:50c0:8003::153, 2606:50c0:8002::153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|2606:50c0:8000::153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4370528 (4.2M) [application/json]\n",
      "Saving to: ‘squad_data/dev-v2.0.json’\n",
      "\n",
      "dev-v2.0.json       100%[===================>]   4.17M  9.44MB/s    in 0.4s    \n",
      "\n",
      "2023-02-15 09:28:25 (9.44 MB/s) - ‘squad_data/dev-v2.0.json’ saved [4370528/4370528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P squad_data https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "!wget -P squad_data https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yebpNBi0_IGw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev-v2.0.json  train-v2.0.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oKT5tQ2M-lGS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Configure the tokenizer and model\n",
    "config = AutoConfig.from_pretrained('roberta-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', do_lower_case=True, use_fast=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('roberta-base', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bKbWCdeQ80Oc"
   },
   "outputs": [],
   "source": [
    "def load_examples(data_dir, data_file, tokenizer, evaluate=False, output_examples=False):\n",
    "    processor = SquadV2Processor()\n",
    "    if evaluate:\n",
    "        examples = processor.get_dev_examples(data_dir, filename=data_file)\n",
    "    else:\n",
    "        examples = processor.get_train_examples(data_dir, filename=data_file)\n",
    "\n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=384,\n",
    "        doc_stride=128,\n",
    "        max_query_length=64,\n",
    "        is_training=not evaluate,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=1,\n",
    "    )\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def train_single_epoch(data_loader, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Function that runs a pytorch based training. For the model training\n",
    "    with question and answering we will need the input_ids,\n",
    "    attention mask, start and ending positions\n",
    "    \"\"\"\n",
    "    # TODO: Set up loss meter\n",
    "    # TODO: Get working with GPU\n",
    "    step_losses = []\n",
    "\n",
    "    # Put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # Description of training\n",
    "    tqdm_loop = tqdm.tqdm(data_loader, leave=True)\n",
    "\n",
    "    for data in tqdm_loop:\n",
    "        # Zero out the gradients from the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get all of the outputs - for this function\n",
    "        # it is specific to the question and answer inputs\n",
    "        input_ids = data[0].to(device)\n",
    "        attention_mask = data[1].to(device)\n",
    "        start_positions = data[3].to(device)\n",
    "        end_positions = data[4].to(device)\n",
    "\n",
    "        # Get the outputs of the model - remember that\n",
    "        # at least with the QA models the first output of the\n",
    "        # model will be the loss\n",
    "        outputs = model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions,\n",
    "        )\n",
    "\n",
    "        # Gather the loss\n",
    "        loss = outputs.loss\n",
    "        step_losses.append(loss)\n",
    "\n",
    "        # Calculate the gradients in the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the gradients with the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # tqdm description\n",
    "        tqdm_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return step_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5pDPIvRE-RFY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 35/35 [00:03<00:00, 10.88it/s]\n",
      "convert squad examples to features: 100%|█| 11873/11873 [00:54<00:00, 219.34it/s\n",
      "add example index and unique id: 100%|█| 11873/11873 [00:00<00:00, 518841.97it/s\n"
     ]
    }
   ],
   "source": [
    "# Create path variables\n",
    "data_dir = 'squad_data'\n",
    "train_data_file = 'train-v2.0.json'\n",
    "validation_data_file = 'dev-v2.0.json'\n",
    "create_training_data = False\n",
    "\n",
    "# Create the training dataset\n",
    "if create_training_data:\n",
    "    train_dataset = load_examples(\n",
    "        data_dir=data_dir,\n",
    "        data_file=train_data_file,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate=False,\n",
    "        output_examples=False,\n",
    "    )\n",
    "    torch.save(train_dataset, 'train_dataset.pt')\n",
    "else:\n",
    "    train_dataset = torch.load('train_dataset.pt')\n",
    "\n",
    "# Create the validation set\n",
    "validation_dataset, validation_examples, validation_features = load_examples(\n",
    "    data_dir=data_dir,\n",
    "    data_file=validation_data_file,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate=True,\n",
    "    output_examples=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GA2idIeuorlJ"
   },
   "outputs": [],
   "source": [
    "training_dataset = train_dataset[:(len(train_dataset) - 10000)]\n",
    "test_dataset = train_dataset[(len(train_dataset) - 10000):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "alQ_x9KzpDyS"
   },
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that builds the encodings for the tokens\n",
    "    from the Squad V2 dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, mode=\"training\"):  # noqa\n",
    "        self.data = data\n",
    "        self.input_ids = data[0].tolist()\n",
    "        self.attention_mask = data[1].tolist()\n",
    "        self.mode = mode\n",
    "\n",
    "        # If mode is training then we need to extract\n",
    "        # the start and stop positions\n",
    "        if self.mode == \"training\":\n",
    "            # Add the start and end positions\n",
    "            self.start_positions = data[3].tolist()\n",
    "            self.end_positions = data[4].tolist()\n",
    "\n",
    "    def __len__(self):  # noqa\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):  # noqa\n",
    "        # We need to get the outputs for all of the texts\n",
    "        # Contexts\n",
    "        # Set up input ids to be torch tensors\n",
    "        input_ids = torch.tensor(self.input_ids[idx], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(self.attention_mask[idx], dtype=torch.long)\n",
    "\n",
    "        # Gather outputs\n",
    "        outputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "        if self.mode == \"training\":\n",
    "            start_positions = torch.tensor(self.start_positions[idx], dtype=torch.long)\n",
    "            end_positions = torch.tensor(self.end_positions[idx], dtype=torch.long)\n",
    "\n",
    "            outputs[\"start_positions\"] = start_positions\n",
    "            outputs[\"end_positions\"] = end_positions\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vT57Hip-po2e"
   },
   "outputs": [],
   "source": [
    "training_dataset = SquadDataset(training_dataset, mode='training')\n",
    "test_dataset = SquadDataset(test_dataset, mode='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mi5-5-iSvElT"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "o_bfunYCx7cl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 1779,  222,  ...,    1,    1,    1],\n",
       "         [   0, 2264,  911,  ...,    1,    1,    1],\n",
       "         [   0, 1779,  222,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   0, 2264,   21,  ...,    1,    1,    1],\n",
       "         [   0, 2264,   21,  ...,    1,    1,    1],\n",
       "         [   0, 4993,   69,  ...,    1,    1,    1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'start_positions': tensor([ 84,  77, 154,  69,  87, 103, 144, 109,  86,  93, 148, 150, 166,  93,\n",
       "         147,  70]),\n",
       " 'end_positions': tensor([ 88,  79, 154,  72,  89, 106, 147, 113,  88,  94, 151, 150, 166,  94,\n",
       "         150,  71])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Kzn5Q3iTsOlW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "path = \"./model_weights/text-mining-titans-roberta-qa.pt\"\n",
    "\n",
    "# Set up the device\n",
    "device = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")  # noqa\n",
    ")  # noqa\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Pe53jfI1snww"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def _inner_training_loop(\n",
    "        self,\n",
    "        batch_size=None,\n",
    "        args=None,\n",
    "        resume_from_checkpoint=None,\n",
    "        trial=None,\n",
    "        ignore_keys_for_eval=None\n",
    "    ):\n",
    "        # The first thing we will do just like the training inner loop is get the\n",
    "        # training dataloader\n",
    "        start = time.time()\n",
    "        train_loader = self.get_train_dataloader()\n",
    "        eval_loader = self.get_eval_dataloader()\n",
    "\n",
    "        # Get number of epochs and max steps\n",
    "        number_of_epochs = args.num_train_epochs\n",
    "        max_steps = math.ceil(args.num_train_epochs * len(train_loader))\n",
    "\n",
    "        # In our case we will set our own optimizer internally\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "        # Implement a learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, 1, gamma=0.9)\n",
    "\n",
    "        train_step_losses = []\n",
    "        # Train the model over epochs\n",
    "        for epoch in range(number_of_epochs):\n",
    "            path = f\"./model_weights/text-mining-titans-roberta-qa-cp{epoch}.pt\"\n",
    "            model.train()\n",
    "            train_loss_per_epoch = 0\n",
    "            train_acc_per_epoch = 0\n",
    "\n",
    "#             with tqdm.tqdm(train_loader, unit='batch') as training_epoch:\n",
    "#                 training_epoch.set_description(f'Training epoch {epoch}')\n",
    "            for step, data in enumerate(train_loader):\n",
    "                # Zero out the optimizer\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Set up the inputs\n",
    "                input_ids = data['input_ids'].to(args.device)\n",
    "                attention_mask = data['attention_mask'].to(args.device)\n",
    "                start_positions = data['start_positions'].to(args.device)\n",
    "                end_positions = data['end_positions'].to(args.device)\n",
    "\n",
    "                # Get the outputs of the model\n",
    "                outputs = model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    start_positions=start_positions,\n",
    "                    end_positions=end_positions,\n",
    "                )\n",
    "\n",
    "                # Get the loss\n",
    "                loss = outputs.loss\n",
    "\n",
    "                # Make the backward pass and compute the gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Apply gradients\n",
    "                self.optimizer.step()\n",
    "\n",
    "#                 # Set loss description\n",
    "#                 training_epoch.set_postfix(loss=loss.item())\n",
    "\n",
    "                # Update the training loss per epoch\n",
    "                train_loss_per_epoch += loss.item()\n",
    "                train_step_losses.append(loss.item())\n",
    "                    \n",
    "            # Step with the scheduler after the epoch\n",
    "            self.scheduler.step()\n",
    "            train_loss_per_epoch /= len(train_loader)\n",
    "            \n",
    "            # Save the model\n",
    "            torch.save(model.state_dict(), path)\n",
    "            \n",
    "            # Setup the evaluation process at the end of each epoch\n",
    "            eval_loss_per_epoch = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "#                 with tqdm.tqdm(eval_loader, unit='batch') as eval_epoch:\n",
    "#                     eval_epoch.set_description(f'Evaluation Epoch {epoch}')\n",
    "                    \n",
    "                for eval_step, eval_data in enumerate(eval_loader):\n",
    "                    input_ids = eval_data['input_ids'].to(args.device)\n",
    "                    attention_mask = eval_data['attention_mask'].to(args.device)\n",
    "                    start_positions = eval_data['start_positions'].to(args.device)\n",
    "                    end_positions = eval_data['end_positions'].to(args.device)\n",
    "\n",
    "                    # Get the outputs of the model\n",
    "                    outputs = model(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions,\n",
    "                    )\n",
    "\n",
    "                    # Eval loss\n",
    "                    eval_loss = outputs.loss\n",
    "                    eval_loss_per_epoch += eval_loss.item()\n",
    "\n",
    "                # compute the loss per epoch\n",
    "                eval_loss_per_epoch /= len(eval_loader)\n",
    "                    \n",
    "                # Print the training and evaluation losses\n",
    "                print(f'Train Loss: {train_loss_per_epoch}')\n",
    "                print(f'Eval Loss: {eval_loss_per_epoch}')\n",
    "        \n",
    "        # Get the end time\n",
    "        end = time.time()\n",
    "        print(f'Time: {(end - start) / 60.0}')\n",
    "        \n",
    "        # Save train step losses\n",
    "        train_step_losses = pd.Series(train_step_losses)\n",
    "        train_step_losses.to_csv('train-step-losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xlrBDQRzsyS1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.092692459291882\n",
      "Eval Loss: 0.7974587857119739\n",
      "Train Loss: 0.7103014185318924\n",
      "Eval Loss: 0.7634216941788793\n",
      "Train Loss: 0.5216155593415344\n",
      "Eval Loss: 0.8480326493486762\n",
      "Time: 180.44707897106807\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "import os\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_weights\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BHCippefvqry"
   },
   "outputs": [],
   "source": [
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult\n",
    "import timeit\n",
    "\n",
    "def evaluate(output_dir, model, tokenizer, device, datasets, prefix=\"\"):\n",
    "    batch_size = 4\n",
    "    model_type = 'roberta'\n",
    "    dataset, examples, features = datasets\n",
    "\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    all_results = []\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    for batch in tqdm.tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            if model_type in [\"xlm\", \"roberta\", \"distilbert\", \"camembert\", \"bart\", \"longformer\"]:\n",
    "                del inputs[\"token_type_ids\"]\n",
    "\n",
    "            feature_indices = batch[3]\n",
    "\n",
    "            # Get the predicted outputs\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        for i, feature_index in enumerate(feature_indices):\n",
    "            eval_feature = features[feature_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "            output = [to_list(output[i]) for output in outputs.to_tuple()]\n",
    "\n",
    "            # Some models (XLNet, XLM) use 5 arguments for their predictions, while the other \"simpler\"\n",
    "            # models only use two.\n",
    "            if len(output) >= 5:\n",
    "                start_logits = output[0]\n",
    "                start_top_index = output[1]\n",
    "                end_logits = output[2]\n",
    "                end_top_index = output[3]\n",
    "                cls_logits = output[4]\n",
    "\n",
    "                result = SquadResult(\n",
    "                    unique_id,\n",
    "                    start_logits,\n",
    "                    end_logits,\n",
    "                    start_top_index=start_top_index,\n",
    "                    end_top_index=end_top_index,\n",
    "                    cls_logits=cls_logits,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                start_logits, end_logits = output\n",
    "                result = SquadResult(unique_id, start_logits, end_logits)\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
    "\n",
    "    # Compute predictions\n",
    "    output_prediction_file = os.path.join(output_dir, \"predictions_{}.json\".format(prefix))\n",
    "    output_nbest_file = os.path.join(output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
    "    output_null_log_odds_file = os.path.join(output_dir, \"null_odds_{}.json\".format(prefix))\n",
    "\n",
    "    # TODO: Get defualt inputs for this function\n",
    "    predictions = compute_predictions_logits(\n",
    "        examples,\n",
    "        features,\n",
    "        all_results,\n",
    "        n_best_size=20,\n",
    "        max_answer_length=30,\n",
    "        do_lower_case=True,\n",
    "        output_prediction_file=output_prediction_file,\n",
    "        output_nbest_file=output_nbest_file,\n",
    "        output_null_log_odds_file=output_null_log_odds_file,\n",
    "        verbose_logging=False,\n",
    "        version_2_with_negative=True,\n",
    "        null_score_diff_threshold=0.0,\n",
    "        tokenizer=tokenizer,\n",
    "      )\n",
    "\n",
    "    # Compute the F1 and exact scores.\n",
    "    results = squad_evaluate(examples, predictions)\n",
    "    return results, examples, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "E_BK5QTx2cco"
   },
   "outputs": [],
   "source": [
    "validation_datasets = (validation_dataset, validation_examples, validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8TGBcosjbVO0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Homework_1_⚡️.ipynb  '(results).py'      train-step-losses.csv\r\n",
      " \u001b[0m\u001b[01;34mmodel_weights\u001b[0m/        \u001b[01;34msquad_data\u001b[0m/\r\n",
      " \u001b[01;34mprediction_outputs\u001b[0m/   train_dataset.pt\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p prediction_outputs\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3XmpgnAdb_vX"
   },
   "outputs": [],
   "source": [
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZfIJuoxEZ5-s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3062/3062 [02:02<00:00, 24.96it/s]\n",
      "Writing predictions to: prediction_outputs/predictions_final_evaluation.json\n",
      "Writing nbest to: prediction_outputs/nbest_predictions_final_evaluation.json\n",
      "Writing null_log_odds to: prediction_outputs/null_odds_final_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import os\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "results, examples, predictions = evaluate(\n",
    "    output_dir='prediction_outputs',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    datasets=validation_datasets,\n",
    "    prefix='final_evaluation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Jp8LWWz4dWgh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('exact', 76.77082455992588),\n",
       "             ('f1', 80.39487190517924),\n",
       "             ('total', 11873),\n",
       "             ('HasAns_exact', 77.66531713900135),\n",
       "             ('HasAns_f1', 84.92380467783306),\n",
       "             ('HasAns_total', 5928),\n",
       "             ('NoAns_exact', 75.87888982338099),\n",
       "             ('NoAns_f1', 75.87888982338099),\n",
       "             ('NoAns_total', 5945),\n",
       "             ('best_exact', 76.77082455992588),\n",
       "             ('best_exact_thresh', 0.0),\n",
       "             ('best_f1', 80.39487190517916),\n",
       "             ('best_f1_thresh', 0.0)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.read_csv('train-step-losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses['0'].rolling(30).mean().dropna().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
