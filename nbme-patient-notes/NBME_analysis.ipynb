{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cf2a7-f53e-4790-9f03-c054bf7cb9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first party\n",
    "import ast\n",
    "\n",
    "# third party\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# first party\n",
    "from data import NBMEDataset, build_pseudo_data, load_training_data\n",
    "from model import NBMEModel\n",
    "from utils import (\n",
    "    Configuration,\n",
    "    build_pseudo_predictions,\n",
    "    create_labels_for_scoring,\n",
    "    get_character_probabilities,\n",
    "    get_predictions,\n",
    "    get_score,\n",
    "    get_thresholded_sequences,\n",
    "    training_function,\n",
    "    validation_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1455b62-ff48-4169-8b7d-c2fb34a2e18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Configuration()\n",
    "data = pd.read_csv(\"./nbme_data/train_data_with_pseudo_labels.csv\")\n",
    "data[\"annotation\"] = data[\"annotation\"].apply(ast.literal_eval)\n",
    "data[\"location\"] = data[\"location\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1173055-0c56-4961-bc4a-eb0daf1fd766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_df = data.loc[data[\"fold_number\"] == 4].reset_index(drop=True)\n",
    "valid_patient_notes_texts = valid_df[\"pn_history\"].values\n",
    "valid_labels = valid_df[\"location\"].apply(create_labels_for_scoring)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "valid_dataset = NBMEDataset(valid_df, config)\n",
    "\n",
    "# Training loaders\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=4, shuffle=False, pin_memory=True, drop_last=False\n",
    ")\n",
    "\n",
    "# Get the loss and optimizers and model\n",
    "model = NBMEModel(config=config)\n",
    "model.load_state_dict(torch.load('./models/deberta_v3_base_cpt_epoch_6.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b55283-6495-461f-95bb-85411c04f4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the probability outputs\n",
    "device = torch.device('cuda:1')\n",
    "model = model.to(device)\n",
    "predictions, labels = validation_function(config, valid_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047ff17-1a83-45be-8d46-5ef1dad18151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reshape the predictions and labels\n",
    "samples = len(valid_df)\n",
    "predictions = predictions.reshape((samples, config.max_length))\n",
    "labels = labels.reshape((samples, config.max_length))\n",
    "\n",
    "# Get character probabilities\n",
    "character_probabilities = get_character_probabilities(\n",
    "    valid_patient_notes_texts, predictions, config\n",
    ")\n",
    "\n",
    "# Get results\n",
    "results = get_thresholded_sequences(character_probabilities)\n",
    "preds = get_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71928857-807d-4c7b-b90f-47cd5b51064e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we want to see the actuals vs the predictions\n",
    "from utils import pseudo_label\n",
    "label_preds = []\n",
    "for pred in preds:\n",
    "    locations = list(map(lambda x: f'{x[0]} {x[1]}', pred))\n",
    "    label_preds.append(locations)\n",
    "    \n",
    "valid_df['predicted_location'] = label_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59723926-3d73-40ff-8153-9e5539513825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "pn_num = 16\n",
    "pn_num_mask = valid_df['pn_num'] == pn_num\n",
    "df = valid_df.loc[pn_num_mask].reset_index(drop=True)\n",
    "\n",
    "text = df['pn_history'].unique()[0]\n",
    "features = df['feature_text'].tolist()\n",
    "locations = df['location'].tolist()\n",
    "predicted_locations = df['predicted_location'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff8b63-ae37-434f-8f3e-d91120dd1e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa2dc2-8a63-4048-afde-0630d2d243fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ents = []\n",
    "for location, feature in zip(locations, features):\n",
    "    if len(location) != 0:\n",
    "        for i in location:\n",
    "            start, end = i.split(' ')\n",
    "            start, end = int(start), int(end)\n",
    "            \n",
    "            ents.append({'start': start, 'end': end, 'label': feature})\n",
    "            \n",
    "# Create the doc\n",
    "colors = {\n",
    "    \"Annotation\": \"linear-gradient(90deg, darkviolet, palegreen)\" \n",
    "}\n",
    "doc = {'text': text, 'ents': ents}\n",
    "options = {'colors': colors, 'distance': 200, 'word_spacing': 60}\n",
    "\n",
    "svg = displacy.render(doc, manual=True, style='ent', options=options, jupyter=True, page=True)\n",
    "# output_path = Path('./annotated_example.svg')\n",
    "# output_path.open('w', encoding='utf-8').write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a64678-42ea-4878-8062-ac5881170ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents = []\n",
    "for location, feature in zip(predicted_locations, features):\n",
    "    if len(location) != 0:\n",
    "        for i in location:\n",
    "            start, end = i.split(' ')\n",
    "            start, end = int(start), int(end)\n",
    "            \n",
    "            ents.append({'start': start, 'end': end, 'label': 'Annotation'})\n",
    "            \n",
    "# Create the doc\n",
    "colors = {\n",
    "    \"Annotation\": \"lightblue\" \n",
    "}\n",
    "doc = {'text': text, 'ents': ents}\n",
    "options = {'colors': colors}\n",
    "displacy.render(doc, manual=True, style='ent', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59af97-f8a8-494c-a103-0a23505429b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615388a-4a15-4a93-9b56-fc0b706ed187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_labels[0], preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b98b8d-34a6-475b-b1f2-34225f6eb198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "text = valid_df['pn_history'].values\n",
    "for label, pred, text in zip(valid_labels.tolist(), preds, text):\n",
    "    score = None\n",
    "    true_annotation = []\n",
    "    predicted_annotation = []\n",
    "    if len(label) != 0:\n",
    "        score = get_score([label], [pred])\n",
    "        for i in label:\n",
    "            start, end = i\n",
    "            annotation = text[start:end]\n",
    "            true_annotation.append(annotation)\n",
    "            \n",
    "        for j in pred:\n",
    "            start, end = j\n",
    "            annotation = text[start:end]\n",
    "            predicted_annotation.append(annotation)\n",
    "            \n",
    "    true_annotation = ', '.join(true_annotation)\n",
    "    predicted_annotation = ', '.join(predicted_annotation)\n",
    "        \n",
    "    scores.append((score, true_annotation, predicted_annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd80551-2278-499d-a44e-1a7dc4a16545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame(\n",
    "    scores,\n",
    "    columns=['f1_score', 'true_annotation', 'predicted_annotation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9439ef-e15e-4595-838c-682182d39c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_df.sort_values('f1_score').dropna().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403690bf-6dfa-4d83-a2ab-03e272071beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_df.iloc[829, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc548ea-9047-4205-869c-7294fd1ef4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "ax = performance_df['f1_score'].hist(figsize=(10, 5), bins=20)\n",
    "ax.axvline(performance_df['f1_score'].mean(), color='red')\n",
    "ax.set_title('Distribution of F1 Scores on Holdout')\n",
    "ax.set_xlabel('F1 Score')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4512eeb-ac7b-4ec7-ac9c-b4b08d53722c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_df.loc[performance_df['f1_score'] < 0.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ea6c9-07e9-43ba-a62d-9ad58b1d1a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import shap\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada60488-c0aa-4896-a7b4-9c998a4113c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3611b-17b3-4300-9382-c22e3dbeb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0  # 1885\n",
    "text = valid_df['pn_history'].values[index]\n",
    "feature_text = valid_df['feature_text'].values[index]\n",
    "annotation = valid_df['annotation'].values[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16359770-fdf7-4e4b-a2d1-56cae11174e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    text,\n",
    "    feature_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=466,\n",
    "    padding='max_length',\n",
    "    return_offsets_mapping=False\n",
    ")\n",
    "\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = torch.tensor(v, dtype=torch.long).reshape(1, 466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d5de8-98b0-4df8-8d84-96f0e57a2b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [f'{text}[SEP]{feature_text}']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d435f20-ca24-4fd1-b91e-e1984920f15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_annotation_scorer(annotation):\n",
    "    def f(notes):\n",
    "        out = []\n",
    "        # There will be a bunch of masked notes created\n",
    "        for n in notes:\n",
    "            scores = []\n",
    "            notes, feature = n.split(\"[SEP]\")\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                feature_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=466,\n",
    "                padding='max_length',\n",
    "                return_offsets_mapping=False\n",
    "            )\n",
    "            \n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = torch.tensor(v, dtype=torch.long, device=device).reshape(1, 466)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            predictions = torch.sigmoid(predictions.flatten())\n",
    "            predictions = predictions.reshape((1, 466)).detach().cpu()\n",
    "            \n",
    "            character_probabilities = get_character_probabilities(\n",
    "                [notes], predictions, config\n",
    "            )\n",
    "            results = get_thresholded_sequences(character_probabilities)\n",
    "            preds = get_predictions(results)\n",
    "            score = get_score(annotation['labels'], preds)\n",
    "            scores.append(score)\n",
    "            out.append(scores)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    f.output_names = annotation['annotation']\n",
    "    return f\n",
    "\n",
    "annotations = {\n",
    "    'labels': [valid_labels[index]],\n",
    "    'annotation': annotation,\n",
    "}\n",
    "f_annotation = make_annotation_scorer(annotation=annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e78b4-79f8-4727-8727-712e4e3d1d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "explainer_answers = shap.Explainer(f_annotation, tokenizer)\n",
    "shap_values_answers = explainer_answers(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da2980-da61-4d9c-82e6-f379530ccd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_answers, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3a7c0-136f-41e0-8c84-45550ea10ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f9627-f8df-44a6-9bca-20c78b19b182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-mining-titans",
   "language": "python",
   "name": "text-mining-titans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
