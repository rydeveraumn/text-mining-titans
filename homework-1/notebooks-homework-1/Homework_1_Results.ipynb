{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54187288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoConfig,\n",
    "    RobertaForQuestionAnswering,\n",
    "    squad_convert_examples_to_features\n",
    ")\n",
    "\n",
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "\n",
    "# Create logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee526ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult\n",
    "import timeit\n",
    "\n",
    "def evaluate(output_dir, model, tokenizer, device, datasets, prefix=\"\"):\n",
    "    batch_size = 4\n",
    "    model_type = 'roberta'\n",
    "    dataset, examples, features = datasets\n",
    "\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    all_results = []\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    for batch in tqdm.tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            if model_type in [\"xlm\", \"roberta\", \"distilbert\", \"camembert\", \"bart\", \"longformer\"]:\n",
    "                del inputs[\"token_type_ids\"]\n",
    "\n",
    "            feature_indices = batch[3]\n",
    "\n",
    "            # Get the predicted outputs\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        for i, feature_index in enumerate(feature_indices):\n",
    "            eval_feature = features[feature_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "            output = [to_list(output[i]) for output in outputs.to_tuple()]\n",
    "\n",
    "            # Some models (XLNet, XLM) use 5 arguments for their predictions, while the other \"simpler\"\n",
    "            # models only use two.\n",
    "            if len(output) >= 5:\n",
    "                start_logits = output[0]\n",
    "                start_top_index = output[1]\n",
    "                end_logits = output[2]\n",
    "                end_top_index = output[3]\n",
    "                cls_logits = output[4]\n",
    "\n",
    "                result = SquadResult(\n",
    "                    unique_id,\n",
    "                    start_logits,\n",
    "                    end_logits,\n",
    "                    start_top_index=start_top_index,\n",
    "                    end_top_index=end_top_index,\n",
    "                    cls_logits=cls_logits,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                start_logits, end_logits = output\n",
    "                result = SquadResult(unique_id, start_logits, end_logits)\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
    "\n",
    "    # Compute predictions\n",
    "    output_prediction_file = os.path.join(output_dir, \"predictions_{}.json\".format(prefix))\n",
    "    output_nbest_file = os.path.join(output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
    "    output_null_log_odds_file = os.path.join(output_dir, \"null_odds_{}.json\".format(prefix))\n",
    "\n",
    "    # TODO: Get defualt inputs for this function\n",
    "    predictions = compute_predictions_logits(\n",
    "        examples,\n",
    "        features,\n",
    "        all_results,\n",
    "        n_best_size=20,\n",
    "        max_answer_length=30,\n",
    "        do_lower_case=True,\n",
    "        output_prediction_file=output_prediction_file,\n",
    "        output_nbest_file=output_nbest_file,\n",
    "        output_null_log_odds_file=output_null_log_odds_file,\n",
    "        verbose_logging=False,\n",
    "        version_2_with_negative=True,\n",
    "        null_score_diff_threshold=0.0,\n",
    "        tokenizer=tokenizer,\n",
    "      )\n",
    "\n",
    "    # Compute the F1 and exact scores.\n",
    "    results = squad_evaluate(examples, predictions)\n",
    "    return results, examples, predictions\n",
    "\n",
    "def load_examples(data_dir, data_file, tokenizer, evaluate=False, output_examples=False):\n",
    "    processor = SquadV2Processor()\n",
    "    if evaluate:\n",
    "        examples = processor.get_dev_examples(data_dir, filename=data_file)\n",
    "    else:\n",
    "        examples = processor.get_train_examples(data_dir, filename=data_file)\n",
    "\n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=384,\n",
    "        doc_stride=128,\n",
    "        max_query_length=64,\n",
    "        is_training=not evaluate,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=1,\n",
    "    )\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee384f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:03<00:00, 11.15it/s]\n",
      "convert squad examples to features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11873/11873 [00:52<00:00, 224.48it/s]\n",
      "add example index and unique id: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11873/11873 [00:00<00:00, 520789.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create path variables\n",
    "data_dir = 'squad_data'\n",
    "validation_data_file = 'dev-v2.0.json'\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', do_lower_case=True, use_fast=False)\n",
    "\n",
    "# Create the validation set\n",
    "validation_dataset, validation_examples, validation_features = load_examples(\n",
    "    data_dir=data_dir,\n",
    "    data_file=validation_data_file,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate=True,\n",
    "    output_examples=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0d079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5240757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3062/3062 [01:58<00:00, 25.91it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3062/3062 [01:59<00:00, 25.61it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3062/3062 [02:00<00:00, 25.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timeit\n",
    "import os\n",
    "from torch.utils.data import SequentialSampler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Results list\n",
    "results_list = []\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# Iterate over the model checkpoints and look at the results\n",
    "for epoch in range(3):\n",
    "    # Configure the tokenizer and model\n",
    "    config = AutoConfig.from_pretrained('roberta-base')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('roberta-base', do_lower_case=True, use_fast=False)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained('roberta-base', config=config)\n",
    "    model.load_state_dict(torch.load(f'./model_weights/text-mining-titans-roberta-qa-cp{epoch}.pt'))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Validation datasets\n",
    "    validation_datasets = (validation_dataset, validation_examples, validation_features)\n",
    "    \n",
    "    # Get the results\n",
    "    results, examples, predictions = evaluate(\n",
    "        output_dir='prediction_outputs',\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device,\n",
    "        datasets=validation_datasets,\n",
    "        prefix=f'checkpoint-{epoch}'\n",
    "    )\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7869d066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact</th>\n",
       "      <th>f1</th>\n",
       "      <th>total</th>\n",
       "      <th>HasAns_exact</th>\n",
       "      <th>HasAns_f1</th>\n",
       "      <th>HasAns_total</th>\n",
       "      <th>NoAns_exact</th>\n",
       "      <th>NoAns_f1</th>\n",
       "      <th>NoAns_total</th>\n",
       "      <th>best_exact</th>\n",
       "      <th>best_exact_thresh</th>\n",
       "      <th>best_f1</th>\n",
       "      <th>best_f1_thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.152110</td>\n",
       "      <td>81.149774</td>\n",
       "      <td>11873</td>\n",
       "      <td>70.175439</td>\n",
       "      <td>76.179363</td>\n",
       "      <td>5928</td>\n",
       "      <td>86.105971</td>\n",
       "      <td>86.105971</td>\n",
       "      <td>5945</td>\n",
       "      <td>78.152110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.149774</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.716415</td>\n",
       "      <td>82.041429</td>\n",
       "      <td>11873</td>\n",
       "      <td>74.156545</td>\n",
       "      <td>80.816107</td>\n",
       "      <td>5928</td>\n",
       "      <td>83.263246</td>\n",
       "      <td>83.263246</td>\n",
       "      <td>5945</td>\n",
       "      <td>78.716415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.041429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.770825</td>\n",
       "      <td>80.394872</td>\n",
       "      <td>11873</td>\n",
       "      <td>77.665317</td>\n",
       "      <td>84.923805</td>\n",
       "      <td>5928</td>\n",
       "      <td>75.878890</td>\n",
       "      <td>75.878890</td>\n",
       "      <td>5945</td>\n",
       "      <td>76.770825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.394872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exact         f1  total  HasAns_exact  HasAns_f1  HasAns_total  \\\n",
       "0  78.152110  81.149774  11873     70.175439  76.179363          5928   \n",
       "1  78.716415  82.041429  11873     74.156545  80.816107          5928   \n",
       "2  76.770825  80.394872  11873     77.665317  84.923805          5928   \n",
       "\n",
       "   NoAns_exact   NoAns_f1  NoAns_total  best_exact  best_exact_thresh  \\\n",
       "0    86.105971  86.105971         5945   78.152110                0.0   \n",
       "1    83.263246  83.263246         5945   78.716415                0.0   \n",
       "2    75.878890  75.878890         5945   76.770825                0.0   \n",
       "\n",
       "     best_f1  best_f1_thresh  \n",
       "0  81.149774             0.0  \n",
       "1  82.041429             0.0  \n",
       "2  80.394872             0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_results = pd.DataFrame(results_list)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c9f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3062/3062 [02:01<00:00, 25.29it/s]\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('roberta-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', do_lower_case=True, use_fast=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('roberta-base', config=config)\n",
    "model.load_state_dict(torch.load(f'./model_weights/text-mining-titans-roberta-qa-cp0.pt'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Validation datasets\n",
    "validation_datasets = (validation_dataset, validation_examples, validation_features)\n",
    "\n",
    "# Get the results\n",
    "results, examples, predictions = evaluate(\n",
    "    output_dir='prediction_outputs',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    datasets=validation_datasets,\n",
    "    prefix=f'checkpoint-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e43ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.metrics.squad_metrics import normalize_answer, compute_exact, compute_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c14f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for example in examples:\n",
    "    qas_id = example.qas_id\n",
    "    gold_answers = [answer['text'] for answer in example.answers if normalize_answer(answer['text'])]\n",
    "    \n",
    "    if not gold_answers:\n",
    "        gold_answers = ['']\n",
    "        \n",
    "    if qas_id not in predictions:\n",
    "        continue\n",
    "        \n",
    "    prediction = predictions[qas_id]\n",
    "    exact_scores = [\n",
    "        (compute_exact(a, prediction), a, prediction, example.context_text, example.question_text, qas_id)\n",
    "        for a in gold_answers\n",
    "    ]\n",
    "    exact_scores = sorted(exact_scores, key=lambda x: x[0], reverse=True)[0]\n",
    "    results.append(exact_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2abcaf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The pound-force has a metric counterpart, less commonly used than the newton: the kilogram-force (kgf) (sometimes kilopond), is the force exerted by standard gravity on one kilogram of mass. The kilogram-force leads to an alternate, but rarely used unit of mass: the metric slug (sometimes mug or hyl) is that mass that accelerates at 1 m·s−2 when subjected to a force of 1 kgf. The kilogram-force is not a part of the modern SI system, and is generally deprecated; however it still sees use for some purposes as expressing aircraft weight, jet thrust, bicycle spoke tension, torque wrench settings and engine output torque. Other arcane units of force include the sthène, which is equivalent to 1000 N, and the kip, which is equivalent to 1000 lbf.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab7a2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact_score</th>\n",
       "      <th>answer</th>\n",
       "      <th>prediction</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the AKS primality test</td>\n",
       "      <td>Miller–Rabin primality test,</td>\n",
       "      <td>The property of being prime (or not) is called...</td>\n",
       "      <td>What is the name of another algorithm useful f...</td>\n",
       "      <td>57296f293f37b319004783a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>histocompatibility</td>\n",
       "      <td></td>\n",
       "      <td>In the mid-1950s, Frank Burnet, inspired by a ...</td>\n",
       "      <td>What is the complex \"two-signal\" activation of...</td>\n",
       "      <td>572a02483f37b3190047864d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>steam turbines</td>\n",
       "      <td>Reciprocating piston type steam engines remain...</td>\n",
       "      <td>What type of engines became popular for power ...</td>\n",
       "      <td>5ad3c061604f3c001a3fef6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cancer, hepatitis, and rheumatoid arthritis</td>\n",
       "      <td></td>\n",
       "      <td>Specialty pharmacies supply high cost injectab...</td>\n",
       "      <td>What types of diseases are specialty drugs oft...</td>\n",
       "      <td>5726f36cdd62a815002e9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>do not have voting rights</td>\n",
       "      <td></td>\n",
       "      <td>Commissioners have various privileges, such as...</td>\n",
       "      <td>Can the President of the Council vote on impor...</td>\n",
       "      <td>57264e455951b619008f6f69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>quantum mechanics.</td>\n",
       "      <td>However, attempting to reconcile electromagnet...</td>\n",
       "      <td>What theory led to quantum electromagnetics?</td>\n",
       "      <td>5ad28237d7d075001a429821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Uptake of O 2 from the air is the essential pu...</td>\n",
       "      <td>Uptake of O\\n2 from the air is the essential p...</td>\n",
       "      <td>What is the essential purpose of supplementati...</td>\n",
       "      <td>5ad25e70d7d075001a428f1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>fern</td>\n",
       "      <td>Several commemorative events take place every ...</td>\n",
       "      <td>What type of flower is sought on Wianki?</td>\n",
       "      <td>5ad500e95b96ef001a10a916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>can produce both eggs and sperm, meaning it ca...</td>\n",
       "      <td>hermaphrodites—a single animal can produce bot...</td>\n",
       "      <td>Most species are hermaphrodites—a single anima...</td>\n",
       "      <td>What is unique about  a hermaphrodite?</td>\n",
       "      <td>5725c57a89a1e219009abe5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>carbon dioxide</td>\n",
       "      <td></td>\n",
       "      <td>Oxygen is present in the atmosphere in trace q...</td>\n",
       "      <td>In what compound is oxygen found in small amou...</td>\n",
       "      <td>571ce7f25efbb31900334e3e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exact_score                                             answer  \\\n",
       "0            0                             the AKS primality test   \n",
       "1            0                                 histocompatibility   \n",
       "2            0                                                      \n",
       "3            0        cancer, hepatitis, and rheumatoid arthritis   \n",
       "4            0                          do not have voting rights   \n",
       "5            0                                                      \n",
       "6            0                                                      \n",
       "7            0                                                      \n",
       "8            0  can produce both eggs and sperm, meaning it ca...   \n",
       "9            0                                     carbon dioxide   \n",
       "\n",
       "                                          prediction  \\\n",
       "0                       Miller–Rabin primality test,   \n",
       "1                                                      \n",
       "2                                     steam turbines   \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                 quantum mechanics.   \n",
       "6  Uptake of O 2 from the air is the essential pu...   \n",
       "7                                               fern   \n",
       "8  hermaphrodites—a single animal can produce bot...   \n",
       "9                                                      \n",
       "\n",
       "                                             context  \\\n",
       "0  The property of being prime (or not) is called...   \n",
       "1  In the mid-1950s, Frank Burnet, inspired by a ...   \n",
       "2  Reciprocating piston type steam engines remain...   \n",
       "3  Specialty pharmacies supply high cost injectab...   \n",
       "4  Commissioners have various privileges, such as...   \n",
       "5  However, attempting to reconcile electromagnet...   \n",
       "6  Uptake of O\\n2 from the air is the essential p...   \n",
       "7  Several commemorative events take place every ...   \n",
       "8  Most species are hermaphrodites—a single anima...   \n",
       "9  Oxygen is present in the atmosphere in trace q...   \n",
       "\n",
       "                                            question                        id  \n",
       "0  What is the name of another algorithm useful f...  57296f293f37b319004783a6  \n",
       "1  What is the complex \"two-signal\" activation of...  572a02483f37b3190047864d  \n",
       "2  What type of engines became popular for power ...  5ad3c061604f3c001a3fef6f  \n",
       "3  What types of diseases are specialty drugs oft...  5726f36cdd62a815002e9600  \n",
       "4  Can the President of the Council vote on impor...  57264e455951b619008f6f69  \n",
       "5       What theory led to quantum electromagnetics?  5ad28237d7d075001a429821  \n",
       "6  What is the essential purpose of supplementati...  5ad25e70d7d075001a428f1c  \n",
       "7           What type of flower is sought on Wianki?  5ad500e95b96ef001a10a916  \n",
       "8             What is unique about  a hermaphrodite?  5725c57a89a1e219009abe5e  \n",
       "9  In what compound is oxygen found in small amou...  571ce7f25efbb31900334e3e  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results, columns=['exact_score', 'answer', 'prediction', 'context', 'question', 'id'])\n",
    "df = df.loc[df['exact_score'] == 0].sample(frac=1.0).reset_index(drop=True)\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
